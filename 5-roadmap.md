# Getting it done

If FSA is meant to face these challenges, we must bring this work from basic research, through various legitimation steps, to policy proposals with broad support among experts and the public, and finally to broad implementation in new algorithms, institutions, and mechanisms—all in time to head off the socio-technical threats before AI agents cause widespread harms.

Theoretical research alone in the five areas outlined above is not sufficient. For an AI lab to adopt a mechanism built on these new foundations, three key conditions must be met:

1. Expert consensus must exist that the solution is the best available approach
2. A clear flagship implementation must exist as a concrete example
3. There must be widespread demand for the solution demonstrated by the flagship example

The absence of any one condition significantly reduces the likelihood of adoption. Expert consensus without implementations risks being dismissed as theoretically intractable. Flagship examples without public demand will likely be deemed too risky for adoption. Public demand without flagship examples often fails to produce change.

The first phase focuses on developing rigorous theories, formalisms, and prototypes demonstrating the viability of explicit norm- and value-based AI and institution design. This requires validating prototypes through various legitimation tests—making formal claims about optimality and robustness while gathering data about small-scale deployments, user experience, and legitimacy.

In parallel, we must cultivate a strong interdisciplinary community—spanning scholars, technologists, and policymakers—to establish clear expert agreement around these novel frameworks, while launching targeted real-world pilots.This involves creating advisory networks and facilitating frequent meetings between researchers and implementers. Each solution will be distilled into concise policy or product recommendations supported by the relevant research.

We'll also need to find suitable venues for real-world deployments across our key domains:

- **Market interventions**: We can work with exchanges or market infrastructure providers to implement value-aligned mechanisms in real-world settings, perhaps as pilot projects or within specific submarkets.

- **Democratic interventions**: We can engage with forward-looking jurisdictions (e.g., Estonia, Norway, Taiwan) prepared to pilot innovative approaches to AI governance, such as value-based AI regulatory infrastructure.

- **Morally-competent agents**: We can partner with financial marketplaces or corporate suppliers willing to trial systems restricted to normatively competent AI agents.

These flagship implementations need not be deployed by the largest countries or top AI labs, but they must deliver robust successes that can generate positive feedback cycles between implementation success and broader adoption: successful implementations generate increased stakeholder demand, which in turn creates opportunities for more ambitious implementations across additional domains.
