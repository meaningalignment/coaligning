# Research & Implementation Roadmap

We here coin the term "Full-Stack Alignment" to cover three things:

- First, the provocative suggestion that many socio-technical alignment challenges can be made tractable by migrating from preference/utility frameworks to a new institution design toolkit based on explicit modeling of norms and values.

    Hopefully our provocative suggestion—that many socio-technical alignment challenges can be made tractable by migrating from preference/utility frameworks to a new institution design toolkit based on explicit modeling of norms and values—now appears more plausible.

- Secondly, the unfortunate fact that, unless we simultaneously align AI models themselves and institutions at various levels of the stack, the incentives at one layer (say, geopolitics) will produce pressure to misalign the other layers (say, ruthless military AI).
- Finally, we use Full Stack Alignment to refer to a plan — a plan for research and societal transformation: to bring this work all the way from basic research, through various legitimation steps, to policy proposals with broad support among experts and the public, and finally to broad implementation in new algorithms, institutions, and mechanisms — all in time to head off the socio-technical threats listed above before AI agents cause widespread harms.

In the below, we'll briefly sketch what the research and implementation plan will look like. A strategy for moving towards a society with social systems and institutions built on new frameworks for values and norms.

We believe theoretical research alone in the 5 areas outlined above is not sufficient. For an AI lab to adopt a mechanism built on these new foundations, three key conditions must be met: expert consensus must exist that the solution is the best available approach, a clear flagship implementation must exist as a concrete example, and there must be widespread demand for the solution demonstrated by the flagship example.

If there is expert consensus but no clear flagship example to point to, a solution would likely be deemed intractable in the real world. If there is a clear flagship example, but no public demand for it, it is likely deemed too risky. If there is clear public demand but no flagship example, it will likely be ignored (public outcry around global warming without clear expert consensus and policy implementation pathway didn't lead to the change the public was hoping for).

Therefore, our general approach is to systematically move work on full-stack alignment for all of the 5 fields we have covered from research to implementation.

## 5.1 Fundamental Research

Rigorous theories, formalisms, and prototypes demonstrating the viability of explicit norm- and value-based institution design.

The goal of the research is to prove out viable solutions to the full-stack alignment challenges above. In some cases, this means new techniques and formalisms need to be developed. In every case, researchers will need to build proof-of-concept systems/mechanisms, and put them through a variety of legitimating tests and proofs—making formal claims about optimality, robustness, etc, and gathering data about small-scale deployments, user experience, legitimacy, etc.

## 5.2 Expert Consensus & Flagship Real-World Implementations

Cultivating a strong interdisciplinary community—spanning scholars, technologists, and policymakers—to establish clear expert agreement around these novel frameworks.

Launch targeted real-world pilots—such as value-aligned market systems, experimental democratic platforms, or morally-competent AI deployments—to serve as proof-of-concept demonstrations.

Once our solutions appear viable, we'll need consensus among policymakers and decision-makers that this is the right approach. We'll build that consensus via advisory networks, frequent meetings between researchers and implementers, and demonstrations. We'll distill each solution into a concise policy or product recommendation, gathering up the related research.

We'll also hunt for opportunities for real-world deployments:

- With the **market interventions**, we'll find exchanges or market infrastructure providers that have the power to implement them in real-world settings, perhaps as a pilot project or within a submarket.
- With **democratic interventions**, we'll find early-adopter polities, like Estonia or Norway, ready to try something new, like an emergency AI regulator.
- With work on **morally-competent agents**, we can find a financial marketplace that will trial being only open to such agents, or a corporate supplier for them.

These flagship implementors do not need to be from the largest countries or the top AI labs, but they must be robust successes that others can point to, pointing the way to the future.

These flagship deployments will prove these systems viable in the real-world, but they could do more than that. [Footnote about rhetoric / use flywheel]

![image.png](attachment:e552ad4e-ffc8-470e-8e12-d98b314e73a3:image.png)
