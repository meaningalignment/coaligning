\documentclass[numbers]{article}
\usepackage[final]{neurips_2023}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{longtable}

% Adjust list indentation
\setlist{leftmargin=*}
\setlist[enumerate]{label=\arabic*., topsep=0pt, parsep=0pt}
\setlist[itemize]{topsep=0pt, parsep=0pt}

% Table settings
\setlength{\LTcapwidth}{\textwidth}
\setlength{\tabcolsep}{4pt}

% NeurIPS settings
% Camera-ready version is set in document class options

% Title and author information
\title{Co-aligning AI and Institutions: Prospects for Full-Stack Alignment}

\author{
  XuanJoe Klingefjord Lowe\\
  Meaning Alignment\\
  % Add other authors similarly
}

\begin{document}

\maketitle

\begin{abstract}
AI systems embedded in our social institutions create a dangerous misalignment: even if each AI faithfully serves its users' stated preferences, the resulting institutional dynamics can systematically undermine our deeper human values. Current approaches to this sociotechnical challenge fall into two inadequate paradigms: the ``Standard Institution Design Toolkit'' (SIDT), which models humans as utility-maximizing agents with fixed preference orderings, and naive value-representations that encode norms as unstructured text vulnerable to drift and manipulation. We introduce Full-Stack Alignment (FSA)—a framework for co-aligning AI systems with human institutions using structured, accountable representations of values and norms. FSA combines two complementary strategies: identifying patterns of normative convergence that distinguish authentic values from manipulated preferences, and developing structural representations that formalize how values should be encoded and reasoned with. We demonstrate through five case studies—AI value stewardship, normatively competent agents, win-win negotiation, meaning-preserving economic mechanisms, and democratic regulation—how FSA transforms intractable alignment problems into tractable engineering challenges. Beyond technical innovation, FSA represents an institutional paradigm shift: from thin models of rationality that flatten human values into preference curves or arbitrary text, to thick models of choice that capture the rich texture of normative reasoning and make AI-human relationships accountable to the values we refuse to trade away. We conclude with a research roadmap for moving from theoretical foundations to practical implementation across multiple domains.
\end{abstract}

% Include all sections in the right order
\input{introduction}
\input{existing_toolkits}
\input{new_toolkit}
\input{case_studies}
\input{roadmap}
\input{conclusion}
\input{related_work}

\renewcommand{\bibsection}{\section*{References}}
\setlength{\bibsep}{0.0pt}
\bibliographystyle{unsrtnat}
\bibliography{real}

\end{document}